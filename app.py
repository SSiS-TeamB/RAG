import time
import streamlit as st
from chromaVectorStore import ChromaVectorStore
from rag import RAGPipeline
from concurrent.futures import ThreadPoolExecutor, as_completed
from streamlit.runtime.scriptrunner import add_script_run_ctx
from PIL import Image

### MultiThreadë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ì‹¤í–‰ìš”ì†Œë§Œ ë”°ë¡œ ëºë‹¤.
## RAGPipeline.invoke, RAGPipeline.retrieve -> ì‹¤í–‰ í›„ time check
def run_pipeline_task(query, task_func):
    start_time = time.time()
    try:
        result = task_func(query)
    except Exception as e:
        result = str(e)
    elapsed_time = time.time() - start_time
    # print(elapsed_time)
    return result, elapsed_time

def page_config():
    """ Execute page config """
    st.set_page_config(
    page_title="Welfare Search Serviece",
    page_icon="âœ¨",
    layout="centered",
    initial_sidebar_state="collapsed",
    )
    #Title
    title = '''<h1 style='text-align: center'>ë³µì§€ ì •ë³´ ê²€ìƒ‰ ì„œë¹„ìŠ¤</h1><br>
    <center>ë‚˜ì—ê²Œ ë”± ë§ëŠ” ë³µì§€ ì •ë³´<br>
    ì´ì œëŠ” ëˆ„êµ¬ë‚˜ ì‰½ê²Œ, ë‚´ ë§ˆìŒëŒ€ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆì–´ìš”!</center><br>
    '''
    st.markdown(title, unsafe_allow_html=True)
    #Image
    img1, img2 = st.columns(2)
    with img1:
        img_ssis = Image.open('image/ssis_logo.png')
        img1.image(img_ssis, use_column_width=True)
    with img2:
        img_BL = Image.open('image/bigleader_logo.png')
        img2.image(img_BL, use_column_width=True)
    st.subheader("", divider='blue')

def vectorstore_config():
    # Settings for semantic_search using vectorstores of langchain
    collection_name = "wf_schema_split"
    persist_directory = "workspace/chroma_storage"            

    vectorstore = ChromaVectorStore(**{
    "collection_name":collection_name, 
    "persist_directory":persist_directory,
    "collection_metadata" : {"hnsw:space":"cosine"}
    })

    return vectorstore

def main() :
    #load page config
    page_config()

    #Query example for user
    st.subheader("ğŸ“Œì´ë ‡ê²Œ ê²€ìƒ‰í•´ë³´ì„¸ìš”!")
    st.info('ì˜ˆì‹œ: "20ëŒ€ ì·¨ì—…ê´€ë ¨ ì œë„"')

    ##### CONTAINERS
    #LLM container
    llm_selector = st.container()
    with llm_selector:
        st.write("")
        st.subheader("âš™ï¸ë‹µë³€ ìƒì„± AI ëª¨ë“œ ì„¤ì •")
        option = st.selectbox(
            "ë” ì •í™•í•œ ë‹µë³€ ìƒì„±ì€ ì¡°ê¸ˆ ëŠë¦´ ìˆ˜ ìˆì–´ìš”.",
            ('ë¹ ë¥¸ ìƒì„±', 'ì •í™•í•œ ìƒì„±'),
            label_visibility="visible",
        )
        # option_speed, option_accuracy = st.columns([0.2, 0.8])
        # gpt_3_5 = option_speed.button("ë¹ ë¥¸ ê²€ìƒ‰")
        # gpt_4 = option_accuracy.button("ì •í™•í•œ ê²€ìƒ‰")
        if option == 'ë¹ ë¥¸ ìƒì„±':
            model = "gpt-3.5-turbo-1106"
            search_name = "ë¹ ë¥¸ ìƒì„±"
        else:
            model = "gpt-4-1106-preview"
            search_name = "ì •í™•í•œ ìƒì„±"
        
    ##### QUERY CONFIG
    query_container = st.container()
    with query_container:
        st.subheader("ğŸ”ê²€ìƒ‰")
        query = st.text_input("Search Bar", placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", label_visibility="hidden")
        search_button = st.button(search_name, use_container_width=True)
        st.divider()
    
    ##### METHOD RESULT CONTAINER
    #invoke container
    invoke_container = st.container()
    with invoke_container:
        st.markdown("### ìƒì„±ëœ ë‹µë³€")
        invoke_empty = st.empty()
        st.divider()
    #retrieve container
    retrieve_container = st.container()
    with retrieve_container:
        st.markdown("### ê´€ë ¨ ë¬¸ì„œ")  
    ##### VECTORSTORE CONFIG
    vectorstore = vectorstore_config()

    #ON Button Event
    if query or search_button:
        model = "gpt-4-1106-preview"
        pipeline = RAGPipeline(vectorstore=vectorstore.vs, embedding=vectorstore.emb, model=model)

        invoke_empty.markdown("ì‹¤í–‰ ì¤‘ ... ")
        with ThreadPoolExecutor() as executor:
            future_invoke = executor.submit(run_pipeline_task, query, pipeline.invoke)
            future_retrieve = executor.submit(run_pipeline_task, query, pipeline.retrieve)
            futures = {future_invoke: 'Invoke', future_retrieve: 'Retrieve'}

            for future in as_completed(futures):
                task_name = futures[future]
                result, elapsed_time = future.result()

                if task_name == 'Invoke':
                    invoke_empty.empty()
                    invoke_empty.markdown(f'{result} \n\n ì‹¤í–‰ ì‹œê°„: {elapsed_time:.2f}ì´ˆ', unsafe_allow_html=True)

                else:
                    empty = retrieve_container.empty()
                    empty.markdown(f'{RAGPipeline.format_docs(result)} \n\n ì‹¤í–‰ ì‹œê°„: {elapsed_time:.2f}ì´ˆ')
            for t in executor._threads:
                add_script_run_ctx(t)
        st.success("ê²€ìƒ‰ ì™„ë£Œ!")

        # progress_text = f'Finding about "{query_text}"...'
        # with st.spinner(progress_text):
        #     placeholder = st.empty()
        #     a = "ê²€ìƒ‰ì¤‘"
        #     placeholder.text(a)
            
        #     ## RAG result
        #     pipeline = RAGPipeline(vectorstore=vectorstore.vs, embedding=vectorstore.emb, model=model)
        #     results_rag = pipeline.invoke(query_text)
        #     a = "ê´€ë ¨ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ. ë‹µë³€ ìƒì„±ì¤‘"
        #     placeholder.text(a)
        #     time.sleep(2)
        #     # semantic_search using vectorstores of langchain
        #     results_vs = pipeline.retrieve(query_text)
        #     a = "ë‹µë³€ ìƒì„± ì™„ë£Œ"
        #     placeholder.text(a)
        #     time.sleep(1)
        #     placeholder.empty()
        #     st.success("ê²€ìƒ‰ ì™„ë£Œ!")
            
        # #Get Answer
        # answer, docs = st.tabs([f"{search_name} ê²°ê³¼", "ê´€ë ¨ ì œë„"])
        # with answer:
        #     st.subheader(f'''
        #                 "{query_text}"ì— ëŒ€í•œ **:blue[{search_name}]** ê²°ê³¼ì…ë‹ˆë‹¤.''')
        #     st.write("")
        #     st.markdown(results_rag)
        # with docs:
        #     st.subheader(f'"{query_text}" ê´€ë ¨ ë³µì§€ ì œë„ì…ë‹ˆë‹¤.')
        #     st.markdown(RAGPipeline.format_docs(results_vs))


#### run -> streamlit run app.py
if __name__ == "__main__":
    main()