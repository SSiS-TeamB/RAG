import streamlit as st
import time
from PIL import Image

# from chromaClient import ChromaClient
from chromaVectorStore import ChromaVectorStore
from rag import RAGPipeline
import math



st.set_page_config(layout='wide')
# add_selectbox = st.sidebar.selectbox("ì™¼ìª½ ì‚¬ì´ë“œë°” Select Box", ("A", "B", "C"))

# ë ˆì´ì•„ì›ƒ
backgroundColor = "#F0F0F0"
empty1, con1, empty2 = st.columns([0.3, 1.0, 0.3])
empty1, con2, con3, empty2 = st.columns([0.3, 0.8, 0.2, 0.3])
empty1, con4, empty2 = st.columns([0.3, 1.0, 0.3])
empty1, con5, con6, empty2 = st.columns([0.3, 0.5, 0.5, 0.3])
empty1, con7, empty2 = st.columns([0.3, 1.0, 0.3])

# Settings for semantic_search using vectorstores of langchain
# vs_info_dict = {"collection_name":"wf_schema", "persist_directory":"workspace/chroma_storage",}
# vs_info_dict = {"collection_name":"wf_schema_no_split", "persist_directory":"workspace/chroma_storage",}
# vector_store = ChromaVectorStore(**vs_info_dict)

with con1:
    st.markdown("<h1 style='text-align: center; color: gray;'>ê²€ìƒ‰ ì—”ì§„ ì‹œìŠ¤í…œ</h1>", unsafe_allow_html=True)
    img_ssis = Image.open('image/ssis_logo.png')
    img_BL = Image.open('image/bigleader_logo.png')
    empty1, col3, col2, col1 = st.columns([3, 0.8, 0.1, 1.2])
    col1.image(img_ssis, use_column_width=True)
    col2.empty()
    col3.image(img_BL, use_column_width=True)
    st.markdown("<p style='text-align: right; color: gray;'>ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”</p>", unsafe_allow_html=True)
#    st.header("Header")
#    st.image("https://static.streamlit.io/examples/cat.jpg", use_column_width=True)

# Settings for semantic_search using vectorstores of langchain
collection_name = "wf_schema_split"
persist_directory = "workspace/chroma_storage"

#### Loading Vectorstore .......
#### ì´ìª½ì— spinner ë„£ì–´ì„œ loading check
with st.spinner():
    vectorstore = ChromaVectorStore(**{
    "collection_name":collection_name, 
    "persist_directory":persist_directory,
    "collection_metadata" : {"hnsw:space":"cosine"}
})


with con2:
    query_text = st.text_input('ê²€ìƒ‰í•˜ì…ˆ', label_visibility='collapsed')
    # query_text = st.text_area("ì´ê±´ ì—¬ëŸ¬ì¤„ ì…ë ¥")

with con3:
    btn_flag = st.button("click")

### button Event
if query_text or btn_flag:
    # semantic_search using "chromadb" module
    # results = chroma_client.semantic_search([query_text], 3)
    start = time.time
 

    
    with con4:
        progress_text = f'Finding about "{query_text}"...'
        with st.status(progress_text, expanded=True) as status:
            st.write("ê²€ìƒ‰ ì¤‘")
            model = "gpt-3.5-turbo-1106"
            rag_pipeline = RAGPipeline(vectorstore=vectorstore.vs, embedding=vectorstore.emb, model=model)
            if rag_pipeline:
                pass
            results_rag = rag_pipeline.invoke(query_text)
            st.write("ê´€ë ¨ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ. ë‹µë³€ ìƒì„±ì¤‘")
            time.sleep(2)
            if results_rag:
                pass
            results_vs = rag_pipeline.retrieve(query_text)
            st.write("ë‹µë³€ ìƒì„± ì™„ë£Œ")
            time.sleep(1)
            if results_vs:
                pass
            status.update(label="ê²€ìƒ‰ ì™„ë£Œ!", state="complete", expanded=False)
            end = time.time
            sec = f"{end-start:.3f} ì´ˆ"
            st.write(sec)
        # progress bar
        # progress_text = f'Finding about "{query_text}"...'
        # my_bar = st.progress(0, text=progress_text)
        ## RAG result
        # model = "gpt-4-1106-preview"
        # model = "gpt-3.5-turbo-1106"
        # rag_pipeline = RAGPipeline(vectorstore=vectorstore.vs, embedding=vectorstore.emb, model=model)
        # st.toast('ë‹µë³€ ìƒì„±ì¤‘!')    
        # for i in range(90):
        #     time.sleep(0.01)
        #     if rag_pipeline:
        #         my_bar.progress(i+1, text=progress_text)

        # st.toast('ì¡°ê¸ˆë§Œ ë” ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!')
        # # results_rag = rag_pipeline.invoke(query_text)
        # for i in range(90,95,1):
        #     time.sleep(0.01)
        #     if results_rag:
        #         my_bar.progress(i+1, text=progress_text)
        # # semantic_search using vectorstores of langchain
        # # results_vs = rag_pipeline.retrieve(query_text)
        # for i in range(95,100,1):
        #     time.sleep(0.01)
        #     if results_vs:
        #         my_bar.progress(i+1, text=progress_text)
        
        # st.toast('ë!', icon='ğŸ‰')
        # time.sleep(1)
        # my_bar.empty()

        # st.subheader('ê²€ìƒ‰ ê²°ê³¼')
        st.markdown("<h2 style='text-align: left; color: white;'>ê²€ìƒ‰ ê²°ê³¼</h2>", unsafe_allow_html=True)
    
    
    

    
    with con5:
        st.write("## ë‹µë³€")
        st.write(results_rag, unsafe_allow_html=True)

    with con6:
        st.markdown("## ê´€ë ¨ ë¬¸ì„œ")
        st.markdown(RAGPipeline.format_docs(results_vs))
        # sp_str = "\n"+'*'*50+"\n"
        # st.write(sp_str.join(doc.page_content for doc in results_vs))
        # print(results_vs)

   
        # print("There are", vectorstore._collection.count(), "in the collection.")
        # results = run_search(search_query)

        # for result in results :
        #     st.title(f'**{result.metadata["title"]}**')
        #     st.markdown(result.page_content)
        #     st.write(result.metadata['tag'].split(','))