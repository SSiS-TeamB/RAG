import streamlit as st
import time
from PIL import Image

# from chromaClient import ChromaClient
from chromaVectorStore import ChromaVectorStore
from rag import RAGPipeline

# def launch():
    # my_bar = st.progress(0, text="ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.") -> ê²€ìƒ‰ ë²„íŠ¼ ëˆ„ë¥´ê³  ë°”ë¡œ ì‹¤í–‰
    #my_bar.progress(percent_complete + 1, text=progress_text) -> ì–´ë””ë‹¤ ë„£ì„ì§€ ê³ ë¯¼
    #my_bar.empty()

st.set_page_config(
page_title="Welfare Search Serviece",
page_icon="âœ¨",
layout="centered",
initial_sidebar_state="collapsed",
)

title = '''<h1 style='text-align: center'>ë³µì§€ ì •ë³´ ê²€ìƒ‰ ì„œë¹„ìŠ¤</h1><br>
<center>ë‚˜ì—ê²Œ ë”± ë§ëŠ” ë³µì§€ ì •ë³´<br>
ì´ì œëŠ” ëˆ„êµ¬ë‚˜ ì‰½ê²Œ, ë‚´ ë§ˆìŒëŒ€ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆì–´ìš”!</center><br>
'''
st.markdown(title, unsafe_allow_html=True)
st.subheader("", divider='blue')

#Query example for user
st.subheader("ğŸ“Œì´ë ‡ê²Œ ê²€ìƒ‰í•´ë³´ì„¸ìš”!")
st.info('ì˜ˆì‹œ: "20ëŒ€ ì·¨ì—…ê´€ë ¨ ì œë„"')

#Select gpt version
with st.container():
    st.write("")
    st.subheader("âš™ï¸ê²€ìƒ‰ ëª¨ë“œ ì„¤ì •")
    option = st.selectbox(
        "ë” ì •í™•í•œ ê²€ìƒ‰ì€ ì¡°ê¸ˆ ëŠë¦´ ìˆ˜ ìˆì–´ìš”.",
        ('ë¹ ë¥¸ ê²€ìƒ‰', 'ì •í™•í•œ ê²€ìƒ‰'),
        label_visibility="visible",
    )
    # option_speed, option_accuracy = st.columns([0.2, 0.8])
    # gpt_3_5 = option_speed.button("ë¹ ë¥¸ ê²€ìƒ‰")
    # gpt_4 = option_accuracy.button("ì •í™•í•œ ê²€ìƒ‰")
    if option == 'ë¹ ë¥¸ ê²€ìƒ‰':
        model = "gpt-3.5-turbo-1106"
        search_name = "ë¹ ë¥¸ ê²€ìƒ‰"
    else:
        model = "gpt-4-1106-preview"
        search_name = "ì •í™•í•œ ê²€ìƒ‰"
    st.divider()

#Enter the query
query_text = st.text_input("Search Bar", placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", label_visibility="hidden")
search_button = st.button(search_name, use_container_width=True)    

#button Event
if query_text or search_button:
    progress_text = f'Finding about "{query_text}"...'
    with st.spinner(progress_text):
        placeholder = st.empty()
        a = "ê²€ìƒ‰ì¤‘"
        placeholder.text(a)
        
        # Settings for semantic_search using vectorstores of langchain
        collection_name = "wf_schema_split"
        persist_directory = "workspace/chroma_storage"            

        vectorstore = ChromaVectorStore(**{
        "collection_name":collection_name, 
        "persist_directory":persist_directory,
        "collection_metadata" : {"hnsw:space":"cosine"}
        })

        # semantic_search using "chromadb" module
        # results = chroma_client.semantic_search([query_text], 3)
        
        ## RAG result
        rag_pipeline = RAGPipeline(vectorstore=vectorstore.vs, embedding=vectorstore.emb, model=model)
        results_rag = rag_pipeline.invoke(query_text)
        a = "ê´€ë ¨ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ. ë‹µë³€ ìƒì„±ì¤‘"
        placeholder.text(a)
        time.sleep(2)
        # semantic_search using vectorstores of langchain
        results_vs = rag_pipeline.retrieve(query_text)
        a = "ë‹µë³€ ìƒì„± ì™„ë£Œ"
        placeholder.text(a)
        time.sleep(1)
        placeholder.empty()
        st.success("ê²€ìƒ‰ ì™„ë£Œ!")
        
    #Get Answer
    answer, docs = st.tabs([f"{search_name} ê²°ê³¼", "ê´€ë ¨ ì œë„"])
    with answer:
        st.subheader(f'''
                    "{query_text}"ì— ëŒ€í•œ **:blue[{search_name}]** ê²°ê³¼ì…ë‹ˆë‹¤.''')
        st.write("")
        st.markdown(results_rag)
    with docs:
        st.subheader(f'"{query_text}" ê´€ë ¨ ë³µì§€ ì œë„ì…ë‹ˆë‹¤.')
        st.markdown(RAGPipeline.format_docs(results_vs))
    # with st.container():
    #     st.divider()
    #     st.subheader(f"{search_name} ê²°ê³¼")
    #     st.markdown(results_rag)
    #     st.divider()
    #     st.markdown("## ê´€ë ¨ ë¬¸ì„œ")
    #     st.markdown(RAGPipeline.format_docs(results_vs))
             

# # launch
# if __name__  == "__main__" :
#     # device_check()
#     launch()